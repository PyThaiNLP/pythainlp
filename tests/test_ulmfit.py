# -*- coding: utf-8 -*-

import unittest

from pythainlp.tokenize import THAI2FIT_TOKENIZER
from pythainlp.ulmfit import (
    THWIKI_LSTM,
    ThaiTokenizer,
    document_vector,
    merge_wgts,
    post_rules_th,
    post_rules_th_sparse,
    pre_rules_th,
    pre_rules_th_sparse,
    process_thai,
)
from pythainlp.ulmfit.preprocess import (
    fix_html,
    lowercase_all,
    remove_space,
    replace_rep_after,
    replace_rep_nonum,
    replace_url,
    replace_wrep_post,
    replace_wrep_post_nonum,
    rm_brackets,
    rm_useless_newlines,
    rm_useless_spaces,
    spec_add_spaces,
    ungroup_emoji,
)
from pythainlp.ulmfit.tokenizer import BaseTokenizer


class TestUlmfitPackage(unittest.TestCase):
    def test_ThaiTokenizer(self):
        self.thai = ThaiTokenizer()
        self.assertIsNotNone(self.thai.tokenizer("‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥"))
        self.assertIsNone(self.thai.add_special_cases(["‡πÅ‡∏°‡∏ß"]))

    def test_BaseTokenizer(self):
        self.base = BaseTokenizer(lang="th")
        self.assertIsNotNone(self.base.tokenizer("‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‡∏Å‡∏≤‡∏£ ‡∏ï‡∏±‡∏î ‡∏Ñ‡∏≥"))
        self.assertIsNone(self.base.add_special_cases(["‡πÅ‡∏°‡∏ß"]))

    def test_load_pretrained(self):
        self.assertIsNotNone(THWIKI_LSTM)

    def test_pre_rules_th(self):
        self.assertIsNotNone(pre_rules_th)

    def test_post_rules_th(self):
        self.assertIsNotNone(post_rules_th)

    def test_pre_rules_th_sparse(self):
        self.assertIsNotNone(pre_rules_th_sparse)

    def test_post_rules_th_sparse(self):
        self.assertIsNotNone(post_rules_th_sparse)

    def test_fix_html(self):
        self.assertEqual(
            fix_html("Some HTML&nbsp;text<br />"), "Some HTML& text\n"
        )

    def test_rm_useless_spaces(self):
        self.assertEqual(
            rm_useless_spaces("Inconsistent   use  of     spaces."),
            "Inconsistent use of spaces.",
        )

    def test_spec_add_spaces(self):
        self.assertEqual(
            spec_add_spaces("I #like to #put #hashtags #everywhere!"),
            "I  # like to  # put  # hashtags  # everywhere!",
        )

    def test_replace_rep_after(self):
        self.assertEqual(replace_rep_after("‡∏ô‡πâ‡∏≠‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢"), "‡∏ô‡πâ‡∏≠‡∏¢xxrep8 ")

    def test_replace_rep_nonum(self):
        self.assertEqual(replace_rep_nonum("‡∏ô‡πâ‡∏≠‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢"), "‡∏ô‡πâ‡∏≠‡∏¢ xxrep ")

    def test_replace_wrep_post(self):
        self.assertEqual(
            replace_wrep_post(["‡∏ô‡πâ‡∏≠‡∏¢", "‡∏ô‡πâ‡∏≠‡∏¢"]), ["xxwrep", "1", "‡∏ô‡πâ‡∏≠‡∏¢"]
        )

        self.assertEqual(
            replace_wrep_post(["‡∏ô‡∏Å", "‡∏Å‡∏≤", "‡∏Å‡∏≤", "‡∏Å‡∏≤"]),
            ["‡∏ô‡∏Å", "xxwrep", "2", "‡∏Å‡∏≤"],
        )

    def test_replace_wrep_post_nonum(self):
        self.assertEqual(
            replace_wrep_post_nonum(["‡∏ô‡πâ‡∏≠‡∏¢", "‡∏ô‡πâ‡∏≠‡∏¢"]), ["xxwrep", "‡∏ô‡πâ‡∏≠‡∏¢"]
        )

        self.assertEqual(
            replace_wrep_post_nonum(["‡∏ô‡∏Å", "‡∏Å‡∏≤", "‡∏Å‡∏≤", "‡∏Å‡∏≤"]),
            ["‡∏ô‡∏Å", "xxwrep", "‡∏Å‡∏≤"],
        )

    def test_remove_space(self):
        self.assertEqual(remove_space([" ", "‡∏ô‡πâ‡∏≠‡∏¢", " ", "."]), ["‡∏ô‡πâ‡∏≠‡∏¢", "."])

    def test_rm_useless_newlines(self):
        self.assertEqual(rm_useless_newlines("text\n\n"), "text ")

    def test_rm_brackets(self):
        self.assertEqual(rm_brackets("()()(‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)"), "(‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)")
        self.assertEqual(rm_brackets("[][][‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]"), "[‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]")
        self.assertEqual(rm_brackets("{}{}{‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°}"), "{‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°}")

    def test_ungroup_emoji(self):
        self.assertEqual(ungroup_emoji("üëçüëçüëç"), ["üëç", "üëç", "üëç"])

    def test_lowercase_all(self):
        self.assertEqual(
            lowercase_all("HeLlO ."), ["h", "e", "l", "l", "o", " ", "."]
        )

    def test_process_thai_sparse(self):
        text = "üëçüëçüëç #AnA ‡∏°‡∏≤‡∏Å‡∏Å‡∏Å‡∏Å ‡∏ô‡πâ‡∏≠‡∏¢‡∏ô‡πâ‡∏≠‡∏¢ ().1146"

        actual = process_thai(text)

        # after pre_rules_th_sparse
        # >>> "üëçüëçüëç # Ana ‡∏°‡∏≤‡∏Å xxrep  ‡∏ô‡πâ‡πâ‡∏≠‡∏¢‡∏ô‡πâ‡∏≠‡∏¢ .1146"
        #
        # after tokenize with word_tokenize(engine="newmm")
        # >>> ["üëçüëçüëç", " ", "#", " ","Ana", " ", "‡∏°‡∏≤‡∏Å", "xxrep",
        #      "  ", "‡∏ô‡πâ‡∏≠‡∏¢", "‡∏ô‡πâ‡∏≠‡∏¢", " ", ".", "1146"]
        #
        # after post_rules_th
        # - remove whitespace token (" ")
        # >>> ["xxwrep, "üëç", "#", "ana", "‡∏°‡∏≤‡∏Å",
        #       "xxrep", "xxwrep", "‡∏ô‡πâ‡∏≠‡∏¢", ".", "1146"]

        expect = [
            "xxwrep",
            "üëç",
            "#",
            "ana",
            "‡∏°‡∏≤‡∏Å",
            "xxrep",
            "xxwrep",
            "‡∏ô‡πâ‡∏≠‡∏¢",
            ".",
            "1146",
        ]

        self.assertEqual(actual, expect)

    def test_process_thai_dense(self):
        text = "üëçüëçüëç #AnA ‡∏°‡∏≤‡∏Å‡∏Å‡∏Å‡∏Å ‡∏ô‡πâ‡∏≠‡∏¢‡∏ô‡πâ‡∏≠‡∏¢ ().1146"

        actual = process_thai(
            text,
            pre_rules=pre_rules_th,
            post_rules=post_rules_th,
            tok_func=THAI2FIT_TOKENIZER.word_tokenize,
        )

        # after pre_rules_th
        # >>> "üëçüëçüëç # Ana ‡∏°‡∏≤‡∏Åxxrep4 ‡∏ô‡πâ‡πâ‡∏≠‡∏¢‡∏ô‡πâ‡∏≠‡∏¢ .1146"
        #
        # after tokenize with word_tokenize(engine="newmm")
        # >>> ["üëçüëçüëç", " ", "#", "Ana", " ", "‡∏°‡∏≤‡∏Å", "xxrep", "4",
        #             " ", "‡∏ô‡πâ‡∏≠‡∏¢", "‡∏ô‡πâ‡∏≠‡∏¢", " ", ".", "1146"]
        # after post_rules_th
        # -- because it performs `replace_wrep_post` before `ungroup_emoji`,
        #    3 repetitive emoji are not marked with special token "xxwrep num"
        #
        # >>> ["üëç", "üëç","üëç", " ", "#", "ana", " ", "‡∏°‡∏≤‡∏Å",
        #       "xxrep", "4", " ", "xxwrep", "1", "‡∏ô‡πâ‡∏≠‡∏¢", " ",
        #       ".", "1146"]

        expect = [
            "üëç",
            "üëç",
            "üëç",
            " ",
            "#",
            " ",
            "ana",
            " ",
            "‡∏°‡∏≤‡∏Å",
            "xxrep",
            "4",
            " ",
            "xxwrep",
            "1",
            "‡∏ô‡πâ‡∏≠‡∏¢",
            " ",
            ".",
            "1146",
        ]

        self.assertEqual(actual, expect)
